# Kaggle 1. Прогнозирование биологического ответа молекул

## Оглавление  
[0. Ссылка на исходные данные](https://www.kaggle.com/competitions/bioresponse/data)   
[1. Описание проекта](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Описание-проекта)  
[2. Какой кейс решаем?](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Какой-кейс-решаем)  
[3. Краткая информация о данных](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Этапы-работы-над-проектом)  
[5. Результаты](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Результаты)    
[6. Выводы](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Выводы) 

### Описание проекта    
Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).

:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


### Какой кейс решаем?    
Практикуемся в эффективной оптимизации гиперпараметров моделей логистической регрессии и случайного леса.

**Метрика качества**     
Используем взвешенное среднее гармоническое между precision и recall: метрику F1.

**Что практикуем**     
1. Учимся применять GridSearchCV, RandomizedSearchCV, Hyperopt и Optuna для поиска оптимальных гиперпараметров моделей. 

:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


### Краткая информация о данных
* Каждая строка в данных представляет молекулу.
* Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ: 0 или 1.
* Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.
  
:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


### Этапы работы над проектом:  
1. Знакомство с данными и разделение их на тренировочную и тестовую выборки.
2. Создание моделей логистической регрессии и случайного леса с гиперпараметрами по умолчанию, фиксация метрик f1 для обеих моделей.
3. LogisticRegression + GriddSearchCV. Поиск оптимальных гиперпараметров, фиксация метрики f1.
4. LogisticRegression + RandomizedSearchCV. Поиск оптимальных гиперпараметров, фиксация метрики f1.
5. RandomForest + Hyperopt. Поиск оптимальных гиперпараметров, фиксация метрики f1.
6. RandomForest + Optuna. Поиск оптимальных гиперпараметров, фиксация метрики f1.
7. Сравнение значений метрики f1, выводы.

:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


### Результаты:  
1. Познакомились с базовыми (GridSearchCV, RandomizedSearchCV) и продвинутыми (Hyperopt, Optuna) методами оптимизации гиперпараметров.
2. Научились настраивать методы оптимизации и обучать модели с их использованием.
3. Сравнили методы оптимизации между собой, выявили их приемущества и недостатки.

:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


### Выводы:  
Использование базовых и продвинутых методов оптимизации позволяет относительно быстро найти оптимальные гиперпараметры модели, тем самым максимизировать целевую метрику.

:arrow_up: [К оглавлению](https://github.com/alpisarev/sf_data_science/tree/main/kaggle_1/#Оглавление)


Если информация по этому проекту покажется вам интересной или полезной, то я буду очень вам благодарен, если отметите репозиторий и профиль ⭐️⭐️⭐️